{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lütfen kaynak belirtmeden bu içeriği tamamen veya kısmen kopyalamayın. Görüş, öneri, şikayet ve işbirliği gibi konular için **kolaydilisleme@gmail.com**_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Stopwords\n",
    "\n",
    "Stopwords, metinlerin içerisinde sıkça geçen fakat tek başlarına pek de bir anlam ifade etmeyen kelimelere denir. Türkçe dilinde bu kelimeler \"ama\", \"bazı\", \"birkaç\" olabilirken İngilizce için \"a\", \"it\", \"but\" olabilir.\n",
    "\n",
    "Stopwords'ler analizin odaklanması gereken daha anlamlı kelimelere dikkat çekmek için genellikle temizlenirler fakat görev spesifik olarak mesela bir makine çevirisi örneğinde temizlememek daha doğru bir sonuç sağlayabilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/enes/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NLTK kütüphanesinin içerisindeki hazır stopwords'leri kullancağız. Tabii ki, NLTK'nin bize sunduğundan daha fazla kelime stopwords olarak sayılabilir. Görev spesifik olarak farklı stopwords'ler de listeye eklenebilir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz', 'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'eğer', 'en', 'gibi', 'hem', 'hep', 'hepsi', 'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne', 'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz', 'şu', 'tüm', 've', 'veya', 'ya', 'yani']\n"
     ]
    }
   ],
   "source": [
    "# Türkçe stopwords\n",
    "turkce_stopwords = stopwords.words('turkish')\n",
    "print(turkce_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "# İngilizce stopwords\n",
    "english_stopwords = stopwords.words('english')\n",
    "print(english_stopwords)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neden Stopwords Temizlenir?\n",
    "\n",
    "- **Anlamlı İçeriğe Erişim:** Stopwords’ler, veri temizleme sürecinde çıkarılarak algoritmaların önemli olmayan bilgilerle uğraşmasını engeller ve böylece daha önemli kelimelere odaklanılmasını sağlar.\n",
    "\n",
    "- **Veri Boyutunu Azaltma:** Stopwords’ler genellikle bir dildeki en yaygın kelimelerdir ve büyük veri setlerinde çok fazla yer kaplarlar. Bu kelimeleri kaldırarak, veri boyutunu önemli ölçüde azaltabiliriz.\n",
    "\n",
    "- **İşlem Süresini Kısaltma:** Stopwords’lerin çıkarılması, metin işleme süresini hızlandırır çünkü daha az kelime üzerinde işlem yapılır.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords Temizleme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Türkçe storpwords temizleme \n",
    "def remove_stopwords_turkish(text):\n",
    "    \n",
    "    stop_words = set(stopwords.words('turkish'))\n",
    "    words = nltk.word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sokrates , antik çağın ünlü filozoflarından biridir . ünlü sözlerinden şöyledir : 'Bilgiğim bir var , hiçbir bilmediğimdir . '\n"
     ]
    }
   ],
   "source": [
    "turkish_text = \"Sokrates, antik çağın ünlü filozoflarından biridir. En ünlü sözlerinden biri şöyledir: 'Bilgiğim bir şey var, o da hiçbir şey bilmediğimdir.'\"\n",
    "filtered_text = remove_stopwords_turkish(turkish_text)\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# İngilizce storpwords temizleme \n",
    "def remove_stopwords_turkish(text):\n",
    "    \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = nltk.word_tokenize(text)\n",
    "    filtered_words = [word for word in words if word.lower() not in stop_words]\n",
    "    filtered_text = ' '.join(filtered_words)\n",
    "    \n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Socrates one famous philosophers ancient era . One famous quotes : 'The thing know know nothing . '\n"
     ]
    }
   ],
   "source": [
    "english_text = \"Socrates is one of the famous philosophers of the ancient era. One of his most famous quotes is: 'The only thing I know is that I know nothing.'\"\n",
    "filtered_text = remove_stopwords_turkish(english_text)\n",
    "print(filtered_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anlamlı İçerik Oranı Bulma\n",
    "Bir metnin ne kadarının anlamlı içerik taşıdığını ölçmek için stopwords'lerin oranından faydalanabiliriz. Örneğin, bir metin analizi uygulamasında, metnin kalitesini veya belirli anahtar kelimelerin yoğunluğunu değerlendirmek için kullanışlı olabilir.\n",
    "\n",
    "Aşağıdaki `content_fraction` fonksiyonu metindeki kelimelerin % kaçının stopwords dışı kelimelerden oluştuğunu döndürür."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9716312056737588\n"
     ]
    }
   ],
   "source": [
    "# Türkçe anlamlı içerik oranı\n",
    "def content_fraction_turkish(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('turkish')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return len(content) / len(text)\n",
    "\n",
    "text = \"Sokrates, antik çağın ünlü filozoflarından biridir. En ünlü sözlerinden biri şöyledir: 'Bilgiğim bir şey var, o da hiçbir şey bilmediğimdir.'\"\n",
    "ratio = content_fraction_turkish(text)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5902777777777778\n"
     ]
    }
   ],
   "source": [
    "# İngilizce anlamlı içerik oranı\n",
    "def content_fraction_english(text):\n",
    "    stopwords = nltk.corpus.stopwords.words('english')\n",
    "    content = [w for w in text if w.lower() not in stopwords]\n",
    "    return len(content) / len(text)\n",
    "\n",
    "text = \"Socrates is one of the famous philosophers of the ancient era. One of his most famous quotes is: 'The only thing I know is that I know nothing.'\"\n",
    "ratio = content_fraction_english(text)\n",
    "print(ratio)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizasyon ve Stopwords Temizliği\n",
    "\n",
    "Aşağıdaki `preprocess_corpus` fonksiyonu girdi metnini stopwords ve noktalama işaretlerinden arındırarak tokenleştirme işlemini gerçekleştirir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sokrates', 'antik', 'çağın', 'ünlü', 'filozoflarından', 'biridir', 'ünlü', 'sözlerinden', 'şöyledir', \"'bilgiğim\", 'bir', 'var', 'hiçbir', 'bilmediğimdir']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    mystopwords = set(stopwords.words(\"turkish\"))\n",
    "    \n",
    "    def remove_stops_digits(tokens):\n",
    "        return [token.lower() for token in tokens if token.lower() not in mystopwords and not token.isdigit() and token not in punctuation]\n",
    "    \n",
    "    return remove_stops_digits(word_tokenize(text))\n",
    "\n",
    "text = \"Sokrates, antik çağın ünlü filozoflarından biridir. En ünlü sözlerinden biri şöyledir: 'Bilgiğim bir şey var, o da hiçbir şey bilmediğimdir.'\"\n",
    "processed_text = preprocess_text(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['socrates', 'one', 'famous', 'philosophers', 'ancient', 'era', 'one', 'famous', 'quotes', \"'the\", 'thing', 'know', 'know', 'nothing']\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def preprocess_text(text):\n",
    "    mystopwords = set(stopwords.words(\"english\"))\n",
    "    \n",
    "    def remove_stops_digits(tokens):\n",
    "        return [token.lower() for token in tokens if token.lower() not in mystopwords and not token.isdigit() and token not in punctuation]\n",
    "    \n",
    "    return remove_stops_digits(word_tokenize(text))\n",
    "\n",
    "text = \"Socrates is one of the famous philosophers of the ancient era. One of his most famous quotes is: 'The only thing I know is that I know nothing.'\"\n",
    "processed_text = preprocess_text(text)\n",
    "print(processed_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kaynaklar\n",
    "- Natural Language Processing with Python (O’Reilly) - Kitap\n",
    "- Practical Natural Language Processing (O’Reilly) - Kitap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Lütfen kaynak belirtmeden bu içeriği tamamen veya kısmen kopyalamayın. Görüş, öneri, şikayet ve işbirliği gibi konular için **kolaydilisleme@gmail.com**_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
